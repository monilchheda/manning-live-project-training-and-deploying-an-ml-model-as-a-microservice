{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 3: Deploying as a FaaS.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8l/Bf17oQhHJpDT60yMHp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monilchheda/manning-live-project-training-and-deploying-an-ml-model-as-a-microservice/blob/master/Part_3_Deploying_as_a_FaaS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNXlnKBwYzmZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "2c3c7d32-c57f-4b84-d667-c497bf765b8b"
      },
      "source": [
        "from nltk import download\n",
        "\n",
        "download('punkt')\n",
        "download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LLQKixNY6kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "stopwords_eng = stopwords.words('english')\n",
        "\n",
        "def extract_features(words):\n",
        "    return [w for w in words if w not in stopwords_eng and w not in punctuation]\n",
        "\n",
        "def bag_of_words(words):\n",
        "    bag = {}\n",
        "    for w in words:\n",
        "        bag[w] = bag.get(w,0)+1\n",
        "    return bag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3loc2cr1Y9rc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "eb9082f8-126d-4573-fee5-2238c5bb6854"
      },
      "source": [
        "import pickle\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    !ls '/content/gdrive/My Drive/Colab Output'\n",
        "    model_file = open('/content/gdrive/My Drive/Colab Output/ML-model-as-service/week2/sa_classifier.pickle','rb')\n",
        "    model = pickle.load(model_file)\n",
        "    model_file.close()\n",
        "    print('Model loaded from /content/gdrive/My Drive/Colab Output')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "ML-model-as-service\n",
            "Model loaded from /content/gdrive/My Drive/Colab Output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8rT1LyHZd1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def get_sentiment(review):\n",
        "    words = word_tokenize(review)\n",
        "    words = extract_features(words)\n",
        "    words = bag_of_words(words)\n",
        "    return model.classify(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQyetcb2ZfNC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6669b99b-634f-48e4-f121-429464a4c9db"
      },
      "source": [
        "positive_review = 'This movie is amazing, with witty dialog and beautiful shots.'\n",
        "print('positive_review: '+get_sentiment(positive_review))\n",
        "\n",
        "negative_review = 'I hated everything about this unimaginitive mess. Two thumbs down!, but its super amazing too'\n",
        "print('negative_review: '+get_sentiment(negative_review))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive_review: pos\n",
            "negative_review: neg\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}